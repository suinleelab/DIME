{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b953d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import feature_groups\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchmetrics import AUROC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "from os import path\n",
    "from dime.data_utils import ROSMAPDataset, get_group_matrix, get_xy, MaskLayerGrouped, data_split\n",
    "from dime.masking_pretrainer import MaskingPretrainer\n",
    "from dime.greedy_model_pl import GreedyCMIEstimatorPL\n",
    "from dime.utils import accuracy, auc, normalize, selection_without_cost\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f15b9",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "\n",
    "use_apoe=False\n",
    "rosmap_feature_names = feature_groups.rosmap_feature_names\n",
    "rosmap_feature_groups = feature_groups.rosmap_feature_groups\n",
    "\n",
    "if not use_apoe:\n",
    "    rosmap_feature_names = [f for f in rosmap_feature_names if f not in ['apoe4_1copy','apoe4_2copies']]\n",
    "\n",
    "feature_groups_dict, feature_groups_mask = get_group_matrix(rosmap_feature_names, rosmap_feature_groups)\n",
    "num_groups = len(feature_groups_mask)\n",
    "\n",
    "cols_to_drop = []\n",
    "if cols_to_drop is not None:\n",
    "    rosmap_feature_names = [item for item in rosmap_feature_names if str(rosmap_feature_names.index(item)) not in cols_to_drop]\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = ROSMAPDataset('./data', split='train', cols_to_drop=cols_to_drop, use_apoe=use_apoe)\n",
    "d_in = train_dataset.X.shape[1]  \n",
    "d_out = len(np.unique(train_dataset.Y))\n",
    "\n",
    "val_dataset = ROSMAPDataset('./data', split='val', cols_to_drop=cols_to_drop, use_apoe=use_apoe)\n",
    "test_dataset = ROSMAPDataset('./data', split='test', cols_to_drop=cols_to_drop, use_apoe=use_apoe)\n",
    "\n",
    "df = pd.read_csv(\"./data/rosmap_feature_costs.csv\", header=None)\n",
    "if use_apoe:\n",
    "    feature_costs = df[1].tolist()\n",
    "else:\n",
    "    feature_costs = df[~df[0].isin(['apoe4_1copy','apoe4_2copies'])][1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da91c28",
   "metadata": {},
   "source": [
    "# Set up Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f467e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up architecture\n",
    "hidden = 128\n",
    "dropout = 0.3\n",
    "d_in = train_dataset.X.shape[1]  # 121\n",
    "d_out = len(np.unique(train_dataset.Y))  # 2\n",
    "print(d_out)\n",
    "# Outcome Predictor\n",
    "predictor = nn.Sequential(\n",
    "    nn.Linear(d_in + num_groups, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout),\n",
    "    nn.Linear(hidden, d_out)).to(device)\n",
    "\n",
    "# CMI Predictor\n",
    "value_network = nn.Sequential(\n",
    "    nn.Linear(d_in + num_groups, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout),\n",
    "    nn.Linear(hidden, num_groups),\n",
    "    nn.Sigmoid()).to(device)\n",
    "\n",
    "# Tie weights\n",
    "# value_network[0] =  predictor[0]\n",
    "# value_network[3] = predictor[3]\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=128, shuffle=False, pin_memory=True,\n",
    "        drop_last=True, num_workers=4)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=128, shuffle=False, pin_memory=True,\n",
    "        drop_last=True, num_workers=4)\n",
    "\n",
    "mask_layer = MaskLayerGrouped(append=True, group_matrix=torch.tensor(feature_groups_mask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f42ff",
   "metadata": {},
   "source": [
    "# Evaluate Penalized Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(1):\n",
    "    results_dict = {\"acc\": {}}\n",
    "    \n",
    "    trained_model_path = f\"<path_to_trained_model>\"\n",
    "    greedy_cmi_estimator = GreedyCMIEstimatorPL.load_from_checkpoint(trained_model_path,\n",
    "                                                                     value_network=value_network,\n",
    "                                                                     predictor=predictor,\n",
    "                                                                     mask_layer=mask_layer,\n",
    "                                                                     lr=1e-3,\n",
    "                                                                    max_features=15,\n",
    "                                                                    eps=0.05,\n",
    "                                                                    loss_fn=nn.CrossEntropyLoss(reduction='none'),\n",
    "                                                                    val_loss_fn=auc,\n",
    "                                                                    eps_decay=True,\n",
    "                                                                    eps_decay_rate=0.2,\n",
    "                                                                    patience=5,\n",
    "                                                                    feature_costs=None,\n",
    "                                                                    use_entropy=True\n",
    "                                                            ).to(device)\n",
    "    \n",
    "    avg_num_features_lambda = []\n",
    "    accuracy_scores_lambda = []\n",
    "    all_masks_lambda=[]\n",
    "    \n",
    "    # Evaluation Mode lambda penalty\n",
    "    lamda_values = [0.000001, 0.00001, 0.00007, 0.0003, 0.0005] + [0.004, 0.016, 0.07] \n",
    "\n",
    "    for lamda in lamda_values:\n",
    "        metric_dict_lambda = greedy_cmi_estimator.evaluate(test_dataloader, performance_func=auc, \n",
    "                                                                        feature_costs=None, use_entropy=True, evaluation_mode='lamda-penalty', lamda=lamda)\n",
    "        accuracy_score = metric_dict_lambda['performance']\n",
    "        final_masks_lambda = metric_dict_lambda['final_masks']\n",
    "        accuracy_scores_lambda.append(accuracy_score)\n",
    "        results_dict['acc'][np.mean(np.sum(final_masks_lambda, axis=1))] = accuracy_score\n",
    "\n",
    "        avg_num_features_lambda.append(np.mean(np.sum(final_masks_lambda, axis=1)))\n",
    "        print(f\"Lambda={lamda}, AUC={accuracy_score}, Avg. num features={np.mean(np.sum(final_masks_lambda, axis=1))}\")\n",
    "\n",
    "        all_masks_lambda.append(final_masks_lambda)\n",
    "        \n",
    "    with open(f'results/rosmap_lambda_ours_trial_{trial}.pkl', 'wb') as f:\n",
    "        pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78dc10",
   "metadata": {},
   "source": [
    "# Evaluate Budget Constrained Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(0, 5):\n",
    "    results_dict = {\"acc\": {}}\n",
    "    trained_model_path = f\"<path_to_trained_model>\"\n",
    "\n",
    "    greedy_cmi_estimator = GreedyCMIEstimatorPL.load_from_checkpoint(trained_model_path_no_costs,\n",
    "                                                                     value_network=value_network,\n",
    "                                                                     predictor=predictor,\n",
    "                                                                     mask_layer=mask_layer,\n",
    "                                                                     lr=1e-3,\n",
    "                                                                    max_features=15,\n",
    "                                                                    eps=0.05,\n",
    "                                                                    loss_fn=nn.CrossEntropyLoss(reduction='none'),\n",
    "                                                                    val_loss_fn=auc,\n",
    "                                                                    eps_decay=True,\n",
    "                                                                    eps_decay_rate=0.2,\n",
    "                                                                    patience=5,\n",
    "                                                                    feature_costs=None,\n",
    "                                                                    use_entropy=True\n",
    "                                                            ).to(device)\n",
    "    avg_num_features_budget = []\n",
    "    accuracy_scores_budget = []\n",
    "    all_masks_budget=[]\n",
    "    max_budget_values = list(range(1, 15, 1))\n",
    "    \n",
    "    for budget in max_budget_values:\n",
    "        metric_dict_budget  = greedy_cmi_estimator.evaluate(test_dataloader, performance_func=auc, \n",
    "                                                                        feature_costs=feature_costs, use_entropy=True, evaluation_mode='fixed-budget', budget=budget)#, selection_func=selection_without_cost)\n",
    "\n",
    "        accuracy_score = metric_dict_budget['performance']\n",
    "        final_masks_budget = metric_dict_budget['final_masks']\n",
    "        accuracy_scores_budget.append(accuracy_score)\n",
    "        avg_num_features_budget.append(np.mean(np.sum(final_masks_budget * feature_costs, axis=1)))\n",
    "        print(f\"Budget={budget}, AUC={accuracy_score}, Avg. num features={np.mean(np.sum(final_masks_budget * feature_costs, axis=1))}\")\n",
    "        results_dict['acc'][np.mean(np.sum(final_masks_budget * feature_costs, axis=1))] = accuracy_score\n",
    "        all_masks_budget.append(final_masks_budget)\n",
    "    \n",
    "    with open(f'results/rosmap_ours_costs_inference_trial_{trial}.pkl', 'wb') as f:\n",
    "        pickle.dump(results_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eefc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adap_selec]",
   "language": "python",
   "name": "conda-env-adap_selec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
